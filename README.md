# Enhancing Complementary Item Recommendations with LLMs

This repository contains the code for the practical training project **"Enhancing Complementary Items Recommendation with LLMs"** (ITMO University, Fall 2025). The project explores augmenting a production-grade recommendation model (EASE) with synthetic data generated by a Large Language Model (LLM) to improve recommendations for rarely purchased items.

**Disclaimer:** Due to Non-Disclosure Agreement (NDA) restrictions, the proprietary dataset, trained models, and specific numerical results cannot be shared publicly. This repository contains the core code for research and demonstration purposes.

---

## Project Overview

The project addresses a key challenge in collaborative filtering models like EASE: providing relevant complementary recommendations for **rarely purchased items**. For products with few recorded transactions, EASE tends to fall back to popularity-based or outdated historical patterns, sometimes leading to irrelevant suggestions.

Our solution uses a self-hosted LLM in a **zero-shot** setting to generate plausible complementary shopping baskets for these rare items. This synthetic data is then used to augment the training process of the EASE model, aiming to improve the relevance of its recommendations for the long tail of the catalog.

### Key Findings & Achievements

*   For items purchased fewer than 3 times in the training data, LLM-based augmentation demonstrably improved the perceived quality of recommendations when judged by an **LLMScore** (LLM-as-a-Judge) metric, which evaluates relevance on a 0-5 scale.
*   A scalable augmentation pipeline was implemented. Generating synthetic baskets for ~5k items takes approximately one hour on a single GPU, making it feasible as a periodic offline task (e.g., run weekly) to refresh data for rare products.
*   Two experimental setups were validated:
    1.  **Augmentation:** Simply adding LLM-generated orders to the training data.
    2.  **Augmentation & Clearing:** Adding synthetic data while *removing* the scarce real orders of rare items to prevent noise.
*   The approach is designed to be non-intrusive. A separate service can generate synthetic baskets, which the production EASE training job can then seamlessly incorporate alongside real transaction data.

---

## Project Architecture

| File | Purpose |
| :--- | :--- |
| **`data.py`** | Contains the data downloader and train-val-test splitting logic. |
| **`models.py`** | Contains the implementation of the core recommendation models (EASE, TopPopular, Random). |
| **`evaluation.py`** | Implements offline evaluation pipelines. Calculates standard metrics (Precision@k, Recall@k, nDCG@k, HitRate@k) and the novel **LLMScore** (LLM-as-a-Judge). |
| **`matching.py`** | Implements the **Matcher** component. Maps unstructured LLM text outputs (product names/descriptions) to valid IDs in the product catalog. Includes retrieval (e.g., BM25, FastText) and ranking modules (uses models from `models.py`). |
| **`generation.py`** | Contains the **LLM Recommender** pipeline. Handles inference with a self-hosted LLM, and the generation of synthetic complementary item lists for given seed products. |
| **`requirements.txt`** | Lists the main Python dependencies for the project. |

---

## Future Work & Potential Improvements

The project establishes a strong foundation for LLM-augmented recommendations. Natural next steps include:
*   Refining the matching step to reduce errors (e.g., distinguishing "nail polish" from "shoe polish").
*   Developing better strategies for handling item variety (e.g., generating multiple similar chocolate bars vs. avoiding multiple identical apples).
*   Mitigating the inherent popularity bias present in both the historical data and the LLM's training corpus.
*   Running online A/B tests to validate the impact on real-world business metrics like conversion rate and average order value.

---

## License & Citation

This project was developed as part of a practical training at ITMO & T-Bank. The code is provided for academic and research purposes. Please cite this work if you use the ideas or architecture.
